{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building and Using a ROC Curve \n",
    "\n",
    "One of the best ways to evaluate how a classifier performs is an ROC curve. (http://en.wikipedia.org/wiki/Receiver_operating_characteristic) \n",
    "\n",
    "![](images/roc_curve.png)\n",
    "\n",
    "To understand what is actually happening with an ROC curve, we can create one ourselves.  Here is pseudocode to plot it.\n",
    "\n",
    "The `probabilities` are values in (0,1) returned from Logistic Regression. The standard default threshold is 0.5 where \n",
    "0-0.5 values are interpreted as the negative class and 0.5-1 values are predicted as the positive class.\n",
    "\n",
    "The `labels` are the true values.\n",
    "\n",
    "```\n",
    "function ROC_curve(probabilities, labels):\n",
    "    Sort instances by their prediction strength (the probabilities)\n",
    "    For every instance in increasing order of probability:\n",
    "        Set the threshold to be the probability\n",
    "        Set everything above the threshold to the positive class\n",
    "        Calculate the True Positive Rate (aka sensitivity or recall)\n",
    "        Calculate the False Positive Rate (1 - specificity)\n",
    "    Return three lists: TPRs, FPRs, thresholds\n",
    "```\n",
    "\n",
    "Recall that the *true positive rate* is\n",
    "\n",
    "```\n",
    " number of true positives     number correctly predicted positive\n",
    "-------------------------- = -------------------------------------\n",
    " number of positive cases           number of positive cases\n",
    "```\n",
    "\n",
    "and the *false positive rate* is\n",
    "\n",
    "```\n",
    " number of false positives     number incorrectly predicted positive\n",
    "--------------------------- = ---------------------------------------\n",
    "  number of negative cases           number of negative cases\n",
    "```\n",
    "\n",
    "You're going to be implementing the `roc_curve` function.\n",
    "\n",
    "Here's some example code that you should be able to use to plot the ROC curve with your function. This uses a fake dataset.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           n_clusters_per_class=2, n_samples=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "tpr, fpr, thresholds = roc_curve(probabilities, y_test)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot of fake data\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write an ROC curve function to compute the above in the cell below, where we have given you the general structure. It should take as input the predicted probabilities and the true labels from the model.\n",
    "\n",
    "2. Run the above code to verify that it's working correctly. You can also validate your correctness against [scikit-learns built-in function](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html).\n",
    "\n",
    "3. Let's see how the roc curve looks on a real dataset. We're going to use the FICO Loan dataset. We want to predict whether or not you get approved for a loan of 12% interest rate given the FICO Score, Loan Length and Loan Amount. Here's the code to load the data:\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/loanf.csv')\n",
    "    y = (df['Interest.Rate'] <= 12).values\n",
    "    X = df[['FICO.Score', 'Loan.Length', 'Loan.Amount']].values\n",
    "    ```\n",
    "\n",
    "    Make sure to split your data into training and testing using sklearn's [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Interpreting the ROC curve \n",
    "\n",
    "For the next section use the logistic regression model you derived for the graduate school admissions dataset.\n",
    "\n",
    "1. Make a plot of the ROC curve (using your function defined in Part 1). We provide code below to load the `grad.csv` dataset. You should specify the dependent variable as `admit` and the independent variables as `gre`,`gpa`, and `rank`.\n",
    "\n",
    "2. Is it possible to pick a threshold where TPR > 60% and FPR < 40%? What is the threshold? *Note that even if it appears to be in the middle of the graph it doesn't make the threshold 0.5.*\n",
    "\n",
    "3. Say we are using this as a first step in the application process. We want to weed out clearly unqualified candidates, but not reject too many candidates. What might be a good choice of threshold? There isn't a single correct answer, so explain your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(probabilities, labels):\n",
    "    '''\n",
    "    INPUT: numpy array, numpy array\n",
    "    OUTPUT: list, list, list\n",
    "\n",
    "    Take a numpy array of the predicted probabilities and a numpy array of theau\n",
    "    true labels.\n",
    "    Return the True Positive Rates, False Positive Rates and Thresholds for the\n",
    "    ROC curve.\n",
    "    '''\n",
    "\n",
    "    '''#Following Algorithm 2 from\n",
    "    http://www.hpl.hp.com/techreports/2003/HPL-2003-4.pdf '''\n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/grad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
